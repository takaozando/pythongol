{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takaozando/compiladores/blob/master/pythongol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pythongol\n",
        "---\n",
        "Linguagem baseada em python com instruções e operadores em português\n",
        "---\n",
        "## Operadores implementados\n",
        "pythongol (python)\n",
        "- Aritmeticos\n",
        "1. mais (+)\n",
        "2. menos (-)\n",
        "3. div (/)\n",
        "4. multip (*)\n",
        "\n",
        "- Relacionais\n",
        "1. maior (>)\n",
        "2. menor (<)\n",
        "3. maiorig (>=)\n",
        "4. menorir (<=)\n",
        "5. diferente (!=)\n",
        "\n",
        "\n",
        "- Atribuição\n",
        "1. recebe (=)\n",
        "\n",
        "\n",
        "- Delimitadores\n",
        "1. Abertura e fechamento de parametros -> ()\n",
        "2. Abertura e fechamento de array -> []\n",
        "3. Separador de parametros -> ,\n",
        "4. Delimitador de funções -> :\n",
        "\n",
        "- Funções\n",
        "1. se,senao,senaose (if,else,elif)\n",
        "    - Os operadores se,senao,senaose só aceitam comparação entre duas variaveis sem a utilização de parenteses. Ex.: se a maior b\n",
        "2. imprime (print)\n",
        "    - A funçaõ imprime aceita qualquer valor desde que sintaticamente correta e com parametros dentro de parenteses. Ex.: imprime ( c ), imprime ('Carlos')\n",
        "3. enquanto (while)\n",
        "    - A função enquanto só aceita comparação entre duas variaveis sem a utilização de parenteses. Ex.: enquanto a < b\n",
        "4. para (for)\n",
        "    - Sintaxe aceita para função para: para carro em carros:\n",
        "\n",
        "---\n",
        "\n",
        "Em cada arquivo txt existe um teste especifico:\n",
        "- No arquivo teste 1.txt é realizado o teste de concatenação entre uma variavel do tipo string e outra do tipo num, retornando uma exceção por não ser possível concatenar str com num.\n",
        "- O arquivo teste 2.txt realiza o teste de sintaxe, resultando em erro de sintaxe na operação de atribuição entre uma variavel e uma função do tipo imprime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "pG7GmJFmVXY3"
      },
      "outputs": [],
      "source": [
        "# Definição dos tokens que serão a saída da análise léxica\n",
        "T_DEFAULT_FUNC = \"<std cmd %s>\"\n",
        "T_OP = \"<op %s>\"\n",
        "T_ARITHMETIC_OP = \"<arithmetic op %s>\"\n",
        "T_RELATIONAL_OP = \"<relational op %s>\"\n",
        "T_ATRIBUITION_OP =  \"<atribuition op %s>\"\n",
        "T_LOGICAL_OP = \"<logical op %s>\"\n",
        "T_NUM = \"<num %s>\"\n",
        "T_STRING = \"<string %s>\"\n",
        "T_IDENTIF = \"<id %s>\"\n",
        "T_DELIMITADOR_PARAM_INI = \"<ini param %s>\"\n",
        "T_DELIMITADOR_PARAM_FIM = \"<fim param %s>\"\n",
        "T_DELIMITADOR_ARRAY_INI = \"<ini array %s>\"\n",
        "T_DELIMITADOR_ARRAY_FIM = \"<fim array %s>\"\n",
        "T_NEWLINE = \"<newline>\"\n",
        "T_TAB = \"<tab>\"\n",
        "T_DOISPONTOS = \"<:>\"\n",
        "T_FUNC_INIT = \"<def %s>\"\n",
        "T_VIRGULA = \"<virg %s>\"\n",
        "T_RETURN = \"<ret %s>\"\n",
        "\n",
        "\n",
        "# Lista de tipos\n",
        "TIPE_DEFAULT_FUNC = \"std cmd\"\n",
        "TIPE_OP = \"op\"\n",
        "TIPE_ARITHMETIC_OP = \"arithmetic op\"\n",
        "TIPE_RELATIONAL_OP = \"relational op\"\n",
        "TIPE_ATRIBUITION_OP =  \"atribuition op\"\n",
        "TIPE_LOGICAL_OP = \"logical op\"\n",
        "TIPE_NUM = \"num\"\n",
        "TIPE_STRING = \"string\"\n",
        "TIPE_IDENTIF = \"id\"\n",
        "TIPE_DELIMITADOR_PARAM_INI = \"ini param\"\n",
        "TIPE_DELIMITADOR_PARAM_FIM = \"fim param\"\n",
        "TIPE_DELIMITADOR_ARRAY_INI = \"ini array\"\n",
        "TIPE_DELIMITADOR_ARRAY_FIM = \"fim array\"\n",
        "TIPE_NEWLINE = \"newline\"\n",
        "TIPE_TAB = \"tab\"\n",
        "TIPE_FUNC_INIT = \"def\"\n",
        "TIPE_VIRGULA = \"virg\"\n",
        "TIPE_RETURN = \"ret\"\n",
        "TIPE_DOISPONTOS = \":\"\n",
        "\n",
        "# Lista de funções intruções da linguagem\n",
        "list_token = {}\n",
        "\n",
        "list_token[\"imprime\"] = {\"translation\": \"print\", \"lexicon\": T_DEFAULT_FUNC, \"tipe\":TIPE_DEFAULT_FUNC}\n",
        "list_token[\"retorna\"] = {\"translation\": \"return\", \"lexicon\": T_DEFAULT_FUNC, \"tipe\":TIPE_DEFAULT_FUNC}\n",
        "list_token[\"enquanto\"] = {\"translation\": \"while\", \"lexicon\": T_DEFAULT_FUNC, \"tipe\":TIPE_DEFAULT_FUNC}\n",
        "list_token[\"para\"] = {\"translation\": \"for\", \"lexicon\": T_DEFAULT_FUNC, \"tipe\":TIPE_DEFAULT_FUNC}\n",
        "list_token[\"se\"] = {\"translation\": \"if\", \"lexicon\":T_DEFAULT_FUNC, \"tipe\":TIPE_DEFAULT_FUNC}\n",
        "list_token[\"em\"] = {\"translation\": \"in\", \"lexicon\": T_DEFAULT_FUNC, \"tipe\":TIPE_DEFAULT_FUNC}\n",
        "\n",
        "list_token[\"funcao\"] = {\"translation\": \"def\", \"lexicon\": T_FUNC_INIT, \"tipe\":TIPE_FUNC_INIT}\n",
        "\n",
        "list_token[\"retorna\"] = {\"translation\": \"return\", \"lexicon\": T_RETURN, \"tipe\":TIPE_RETURN}\n",
        "#************************************************************************************************\n",
        "#Lista de operadores aritmeticos\n",
        "list_token[\"mais\"] = {\"translation\": \"+\", \"lexicon\": T_ARITHMETIC_OP, \"tipe\": TIPE_ARITHMETIC_OP }\n",
        "list_token[\"menos\"] = {\"translation\": \"-\", \"lexicon\": T_ARITHMETIC_OP, \"tipe\": TIPE_ARITHMETIC_OP }\n",
        "list_token[\"multip\"] = {\"translation\": \"*\", \"lexicon\": T_ARITHMETIC_OP, \"tipe\": TIPE_ARITHMETIC_OP }\n",
        "list_token[\"div\"] = {\"translation\": \"/\", \"lexicon\": T_ARITHMETIC_OP, \"tipe\": TIPE_ARITHMETIC_OP }\n",
        "#************************************************************************************************\n",
        "#Lista de operadores relacionais\n",
        "\n",
        "list_token[\"maior\"] = {\"translation\": \">\", \"lexicon\": T_RELATIONAL_OP,\"tipe\": TIPE_RELATIONAL_OP}\n",
        "list_token[\"menor\"] = {\"translation\": \"<\", \"lexicon\": T_RELATIONAL_OP,\"tipe\": TIPE_RELATIONAL_OP}\n",
        "list_token[\"maiorig\"] = {\"translation\": \">=\", \"lexicon\": T_RELATIONAL_OP,\"tipe\": TIPE_RELATIONAL_OP}\n",
        "list_token[\"menorig\"] = {\"translation\": \"<=\", \"lexicon\": T_RELATIONAL_OP,\"tipe\": TIPE_RELATIONAL_OP}\n",
        "list_token[\"diferente\"] = {\"translation\": \"!=\", \"lexicon\": T_RELATIONAL_OP,\"tipe\": TIPE_RELATIONAL_OP}\n",
        "#************************************************************************************************\n",
        "#Lista de operadores de atribuição\n",
        "list_token[\"recebe\"] = {\"translation\": \"=\", \"lexicon\": T_ATRIBUITION_OP, \"tipe\": TIPE_ATRIBUITION_OP}\n",
        "list_token[\"recebemais\"] = {\"translation\": \"+=\", \"lexicon\": T_ATRIBUITION_OP, \"tipe\": TIPE_ATRIBUITION_OP}\n",
        "list_token[\"recebemenos\"] = {\"translation\": \"-=\", \"lexicon\": T_ATRIBUITION_OP, \"tipe\": TIPE_ATRIBUITION_OP}\n",
        "list_token[\"recebevezes\"] = {\"translation\": \"*=\", \"lexicon\": T_ATRIBUITION_OP, \"tipe\": TIPE_ATRIBUITION_OP}\n",
        "list_token[\"recebedividido\"] = {\"translation\": \"/=\", \"lexicon\": T_ATRIBUITION_OP, \"tipe\": TIPE_ATRIBUITION_OP}\n",
        "#************************************************************************************************\n",
        "#Lista de delimitadores\n",
        "list_token[\"(\"] = {\"translation\": \"(\", \"lexicon\": T_DELIMITADOR_PARAM_INI, \"tipe\":TIPE_DELIMITADOR_PARAM_INI}\n",
        "list_token[\")\"] = {\"translation\": \")\", \"lexicon\": T_DELIMITADOR_PARAM_FIM, \"tipe\":TIPE_DELIMITADOR_PARAM_FIM}\n",
        "list_token[\"[\"] = {\"translation\": \"[\", \"lexicon\": T_DELIMITADOR_ARRAY_INI, \"tipe\":TIPE_DELIMITADOR_ARRAY_INI}\n",
        "list_token[\"]\"] = {\"translation\": \"]\", \"lexicon\": T_DELIMITADOR_ARRAY_FIM, \"tipe\":TIPE_DELIMITADOR_ARRAY_FIM}\n",
        "list_token[\",\"] = {\"translation\": \",\", \"lexicon\": T_VIRGULA, \"tipe\": TIPE_VIRGULA}\n",
        "list_token[\":\"] = {\"translation\": \":\", \"lexicon\": T_DOISPONTOS, \"tipe\": TIPE_DOISPONTOS}\n",
        "#************************************************************************************************\n",
        "#Lista de operadores logicos\n",
        "#*************NÃO IMPELEMENTADO****************NÃO IMPELEMENTADO****************NÃO IMPELEMENTADO\n",
        "#list_token[\"E\"] = {\"translation\": \"and\", \"lexicon\": T_LOGICAL_OP, \"tipe\": TIPE_LOGICAL_OP}\n",
        "#list_token[\"OU\"] = {\"translation\": \"or\", \"lexicon\": T_LOGICAL_OP, \"tipe\": TIPE_LOGICAL_OP}\n",
        "#list_token[\"NÃO\"] = {\"translation\": \"not\", \"lexicon\": T_LOGICAL_OP, \"tipe\": TIPE_LOGICAL_OP}\n",
        "#************************************************************************************************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CLASSE TOKEN\n",
        "\n",
        "#Atributos\n",
        "\n",
        "# translation   -> tradução equivalente em python,\n",
        "# lexicon       -> token no formato <'tipo' 'valor>\n",
        "# tipe          -> tipo do token (string, num, id,etc)\n",
        "# value         -> valor do token, obtido do codigo fonte em pythongol\n",
        "\n",
        "# varTipe       -> Utilizado somente em identificadores\n",
        "#                  recebe o tipo da expressão atribuida à variavel (string, num)\n",
        "\n",
        "# identLevel    -> Nível de identação do token\n",
        "\n",
        "# varScope      -> Utilizado somente em identificadores\n",
        "#                  Recebe o escopo em que a variavel foi criada, global, escopo valido ou escopo invalido\n",
        "\n",
        "class Token:\n",
        "    def __init__(self, translation, lexicon, tipe, value=None, varTipe=None,identLevel=None,varScope=None,varValue=None):\n",
        "        self._translation = translation\n",
        "        self._lexicon = lexicon\n",
        "        self._tipe = tipe\n",
        "        self._value = value\n",
        "        self._varTipe = varTipe\n",
        "        self._identLevel = identLevel\n",
        "        self._varScope = varScope\n",
        "        self._varValue = varValue\n",
        "        \n",
        "    @property\n",
        "    def varTipe(self):\n",
        "        return self._varTipe\n",
        "\n",
        "    @varTipe.setter\n",
        "    def varTipe(self, value):\n",
        "        self._varTipe = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokens = [] #Lista com tokens do tipo str no formato <tipo valor>\n",
        "tokens_list = [] #Lista de objetos Token\n",
        "parse_output = [] #Lista de saída do analisador sintatico com tokens do tipo str no formato <tipo valor>\n",
        "declared_identifiers = [] #Lista de identificadores ou variaveis corretamente declaradas\n",
        "inner_tokens = []\n",
        "inner_expressions = []\n",
        "#NÃO IMPLEMENTADO***************NÃO IMPLEMENTADO***************NÃO IMPLEMENTADO***************\n",
        "declared_functions = [] #Lista de funcoes definidas corretamente declaradas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Funções de debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Recebe uma lista de tokens do tipo string e\n",
        "#Exibe a lista de tokens formatados\n",
        "def print_list_elements(elements):\n",
        "    output_str  = \"\"\n",
        "    for element in elements:\n",
        "        if element == \"<newline>\":\n",
        "            output_str += (\"\\n\")\n",
        "            continue\n",
        "        if element == \"<tab>\":\n",
        "            output_str += (\"\\t\")\n",
        "            continue\n",
        "        output_str += (element)\n",
        "\n",
        "    print(output_str)\n",
        "\n",
        "#Exibe a saída de tokens formatados do analisador sintatic\n",
        "def print_output_sintatico():\n",
        "    parse_output_str = \"\"\n",
        "    for element in parse_output:\n",
        "        if element == \"<newline>\":\n",
        "            parse_output_str += (\"\\n\")\n",
        "        if element == \"<tab>\":\n",
        "            parse_output_str += (\"\\t\")\n",
        "    parse_output_str += (element)\n",
        "\n",
        "def printTokensList(tokensList):\n",
        "    parse_output_str = \"\"\n",
        "    for element in tokensList:\n",
        "        if element._tipe == TIPE_NEWLINE:\n",
        "            parse_output_str += (\"\\n\")\n",
        "        if element._tipe == TIPE_TAB:\n",
        "            parse_output_str += (\"\\t\")\n",
        "        parse_output_str += (element._value + \" \")\n",
        "    print(parse_output_str)\n",
        "    \n",
        "\n",
        "#Percorre a lista de objeto Token e\n",
        "#Exibe o tipo da variavel, se o token for um identificador\n",
        "def print_var_tipe():\n",
        "    for tudo in tokens_list:\n",
        "        if tudo.varTipe != None:\n",
        "            print(f\"Token {tudo._value} varTipe: {tudo._varTipe}\")\n",
        "\n",
        "def print_all_lists():\n",
        "    print(tokens)  #Lista com tokens do tipo str no formato <tipo valor>\n",
        "    print(tokens_list)#Lista de objetos Token\n",
        "    print(parse_output) #Lista de saída do analisador sintatico com tokens do tipo str no formato <tipo valor>\n",
        "    print(declared_identifiers)#Lista de identificadores ou variaveis corretamente declaradas\n",
        "    print(declared_functions) #Lista de funcoes definidas corretamente declaradas\n",
        "    print(inner_tokens)\n",
        "    print(inner_expressions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Retorna o nivel de identação da linha\n",
        "#Pausa a contagem ao encontrar qualquer elemento diferente de espaço ou tabulação\n",
        "# 1 representa tab, 0,25 espaço\n",
        "def count_indentation(line):\n",
        "    count = 0\n",
        "    for char in line:\n",
        "        if char == ' ':\n",
        "            count += 0,25\n",
        "        elif char == '\\t':\n",
        "            count += 1\n",
        "        else:\n",
        "            break  \n",
        "    return count\n",
        "\n",
        "#Busca em list_token e\n",
        "#Retorna o valor referente ao token desejado\n",
        "#opções de returnType -> translation, lexicon,tipe\n",
        "def checkToken(token, returnType):\n",
        "  if token in list_token:\n",
        "    return list_token[token][returnType].format(token=token)\n",
        "  elif is_number(token):\n",
        "    return TIPE_NUM\n",
        "  elif token.isidentifier:\n",
        "    return TIPE_IDENTIF\n",
        "  elif ( (token.startswith(\"'\") and token.endswith(\"'\")) or\n",
        "         token.startswith(\"\\\"\") and token.endswith(\"\\\"\") ):\n",
        "    return TIPE_STRING\n",
        "  else:\n",
        "    raise ValueError('Erro de lexico: ' + token)\n",
        "\n",
        "#Verifica com regular expression, se o token é um\n",
        "def is_number(token):\n",
        "    pattern = re.compile(r'^\\d+$')\n",
        "    return bool(pattern.match(token))\n",
        "\n",
        "def clearAllLists():\n",
        "  tokens.clear()#Lista com tokens do tipo str no formato <tipo valor>\n",
        "  tokens_list.clear() #Lista de objetos Token\n",
        "  parse_output.clear() #Lista de saída do analisador sintatico com tokens do tipo str no formato <tipo valor>\n",
        "  declared_identifiers.clear() #Lista de identificadores ou variaveis corretamente declaradas\n",
        "  declared_functions.clear() #Lista de funcoes definidas corretamente declaradas\n",
        "  inner_tokens.clear()\n",
        "  inner_expressions.clear()\n",
        "  tokens.clear() #Clear all tokens\n",
        "\n",
        "def setDefinedVariable(variable, tipe):\n",
        "  variable._varTipe = tipe\n",
        "  declared_identifiers.append(variable)\n",
        "  #print(f\"DEFINED :{declared_identifiers[-1]._value,declared_identifiers[-1]._varTipe}\")\n",
        "\n",
        "def attVarTipe(variable, tipe):\n",
        "    variable._varTipe = tipe\n",
        "\n",
        "def checkDefinedVariablesByValue(value):\n",
        "    for id in declared_identifiers:\n",
        "        if id._value == value:\n",
        "            #print(f\"id {id._value} already defined!\")\n",
        "            return True\n",
        "    #print(f\"id {id} is not defined\")\n",
        "    return False\n",
        "\n",
        "def setDefinedFunction(variable, tipe):\n",
        "    variable._varTipe = tipe\n",
        "    declared_functions.append(variable)\n",
        "    #print(f\"DEFINED :{declared_identifiers[-1]._value,declared_identifiers[-1]._varTipe}\")\n",
        "\n",
        "def checkDefinedFunctionByValue(value):\n",
        "    for id in declared_functions:\n",
        "        if id._value == value:\n",
        "            #print(f\"id {id._value} already defined!\")\n",
        "            return True\n",
        "    #print(f\"id {id} is not defined\")\n",
        "    return False\n",
        "\n",
        "def getVarTipe(elementValue):\n",
        "    for e in declared_identifiers:\n",
        "        if e._value == elementValue:\n",
        "            #print(f\"varTipe do elemento {e._value}: {e._varTipe}\")\n",
        "            return e._varTipe\n",
        "\n",
        "def getParameters(start_index):\n",
        "    inner_index = start_index\n",
        "    inner_parameters = []\n",
        "    #print(\"**************************parse parameters**************************\")\n",
        "    \n",
        "    while (tokens_list[inner_index]._tipe != TIPE_NEWLINE and\n",
        "            tokens_list[inner_index]._tipe != TIPE_DELIMITADOR_PARAM_FIM and\n",
        "            tokens_list[inner_index]._tipe != TIPE_DELIMITADOR_ARRAY_FIM and\n",
        "            tokens_list[inner_index]._tipe != TIPE_DOISPONTOS and\n",
        "            tokens_list[inner_index]._tipe != \"EOF\"):\n",
        "        \n",
        "        inner_parameters.append(tokens_list[inner_index])\n",
        "        inner_index+=1\n",
        "    \n",
        "    #for item in inner_parameters:\n",
        "    #    print(f\"item do inner_parameter {item._value}\")\n",
        "\n",
        "    return inner_parameters\n",
        "\n",
        "def checkParametersReturn(parameters):\n",
        "    right_operand = parameters[2]._value\n",
        "    left_operand = parameters[0]._value\n",
        "    operator = parameters[1]._value\n",
        "    #print(f'checkParametersReturn {left_operand} {operator} {right_operand} ?')\n",
        "    if operator == \"maior\":\n",
        "        #print(left_operand > right_operand)\n",
        "        return (left_operand > right_operand)\n",
        "    elif operator == \"menor\":\n",
        "        #print(left_operand < right_operand)\n",
        "        return (left_operand < right_operand)\n",
        "    elif operator == \"maiorig\":\n",
        "        #print(left_operand >= right_operand)\n",
        "        return (left_operand >= right_operand)\n",
        "    elif operator == \"menorig\":\n",
        "        #print(left_operand <= right_operand)\n",
        "        return (left_operand <= right_operand)\n",
        "    elif operator == \"diferente\":\n",
        "        #print(print(left_operand != right_operand))\n",
        "        return (left_operand != right_operand)\n",
        "    \n",
        "def skipParameters(parameters):\n",
        "    return(len(parameters))\n",
        "\n",
        "def getConditionalBlock(index,initialIdentLevel,skip):\n",
        "    #print(\"************Conditional block chamado em ação************\")\n",
        "    #print(f'CONDITIONALBLOCK: ident level inicial: {initialIdentLevel}')\n",
        "    block_elements = []\n",
        "    while index in range (len(tokens_list)):\n",
        "        previous_token = tokens_list[index - 1]\n",
        "        current_token = tokens_list[index]\n",
        "        next_token = tokens_list[index + 1] if index < len(tokens_list) -1 else None\n",
        "        current_identation = current_token._identLevel\n",
        "        \n",
        "        #print(f'CONDITIONALBLOCK: current token  {current_token._value} ident level: {current_token._identLevel} ')\n",
        "        if current_identation <= initialIdentLevel or current_token._value == \"EOF\":\n",
        "            #print(\"************BREAKADO PARSAO************\")\n",
        "            break\n",
        "        \n",
        "        if not skip:\n",
        "            if current_token._tipe == TIPE_ATRIBUITION_OP:\n",
        "                if next_token._tipe == TIPE_IDENTIF:\n",
        "                    #print(f'atribuindo {next_token._varTipe} a {previous_token._value}')\n",
        "                    setDefinedVariable(previous_token,next_token._varTipe)\n",
        "                else:\n",
        "                    #print(f'atribuindo {next_token._tipe} a {previous_token._value}')\n",
        "                    setDefinedVariable(previous_token,next_token._tipe)\n",
        "        #print(f'CONDITIONALBLOCK: appended na lista: {current_token._value}')\n",
        "        block_elements.append(current_token._value)\n",
        "        index += 1\n",
        "    #print(f'\\n\\n\\nCONDITIONALBLOCK: tamanho do bloco condicional: {len(block_elements)}')\n",
        "    return len(block_elements ) +2\n",
        "\n",
        "\n",
        "def parse_identation(listTokens):\n",
        "    index = 0\n",
        "    while index in range(len(listTokens)):\n",
        "        previous_token = listTokens[index - 1] if index >= 1 else None\n",
        "        current_token = listTokens[index]\n",
        "        next_token = listTokens[index + 1]  if index < len(listTokens) - 1 else \"Sepa que é aqui\"\n",
        "        current_identation = current_token._identLevel\n",
        "        #print(f'current_token: {current_token._value}')\n",
        "        #print(f'current_token: {current_token._tipe}')\n",
        "        if current_token._value == \"EOF\":\n",
        "            break\n",
        "        if \":\" in current_token._value:\n",
        "            \n",
        "            if ( (not next_token) or (next_token._tipe != \"EOF\" and next_token._tipe != TIPE_NEWLINE) ): \n",
        "                raise ValueError(f'Token {next_token._value} inesperado após {current_token._value}')\n",
        "            \n",
        "            if listTokens[index + 2]._identLevel <= current_identation:\n",
        "                raise ValueError(f'Erro de idenntação: Esperado identação no inicio da linha')\n",
        "        \n",
        "        elif (not \":\" in current_token._value and next_token._tipe == TIPE_NEWLINE):\n",
        "                if listTokens[index + 2]._identLevel > current_identation:\n",
        "                    raise ValueError(f'Erro de idenntação: Identação inesperada')\n",
        "            \n",
        "        index += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "WS9zYHnMTwH1"
      },
      "outputs": [],
      "source": [
        "# ANALISADOR LÉXICO\n",
        "def lexicon(arquivo):\n",
        "    with arquivo:\n",
        "        for linha_numero, linha in enumerate(arquivo, start=1):\n",
        "\n",
        "            #Identifica tokens,  tabulações e quebras de linha\n",
        "            tokens_split = re.findall(r\"'[^']*'|\\S+|[\\(\\)\\[\\]:,]+|\\t|\\n\", linha)\n",
        "            line_ident_level = count_indentation(tokens_split)\n",
        "            for token in tokens_split:\n",
        "                if token:\n",
        "                    if token.startswith(\"'\") and token.endswith(\"'\"):\n",
        "                        tokens_list.append(Token(token, token, TIPE_STRING,token,None,line_ident_level,None))\n",
        "                        tokens.append(T_STRING % token)\n",
        "                    elif token.startswith(\"'\") and not token.endswith(\"'\"):\n",
        "                        raise ValueError(f'Erro léxico na linha {linha_numero}: {linha}\\n {token}')\n",
        "                    elif token == '\\t':\n",
        "                        tokens.append(T_TAB)\n",
        "                        tokens_list.append(Token('\\t', \"<tab>\", \"tab\",'\\t',None,line_ident_level,None))\n",
        "                    elif token == '\\n':\n",
        "                        tokens.append(T_NEWLINE)\n",
        "                        tokens_list.append(Token('\\n', \"<newline>\", \"newline\",token,None,line_ident_level,None))\n",
        "                    elif token == ':':\n",
        "                        tokens.append(T_DOISPONTOS)\n",
        "                        tokens_list.append(Token(checkToken(token,\"translation\"), checkToken(token,\"lexicon\"), checkToken(token,\"tipe\"),token,None,line_ident_level,None))\n",
        "                    else:\n",
        "                        if checkToken(token, \"lexicon\") != \"\":\n",
        "                                if checkToken(token,\"tipe\") == TIPE_IDENTIF:\n",
        "                                    tokens_list.append(Token(token, checkToken(token,\"lexicon\"), checkToken(token,\"tipe\"),token,None,line_ident_level,\"global\")) \n",
        "                                    tokens.append(\"<\" + tokens_list[-1]._tipe + \" \" + token + \">\")\n",
        "                                elif checkToken(token,\"tipe\") == TIPE_NUM:\n",
        "                                    tokens_list.append(Token(token, checkToken(token,\"lexicon\"), checkToken(token,\"tipe\"),token,None,line_ident_level,None)) \n",
        "                                    tokens.append(\"<\" + tokens_list[-1]._tipe + \" \" + token + \">\")\n",
        "                                else:\n",
        "                                    tokens_list.append(Token(checkToken(token,\"translation\"), checkToken(token,\"lexicon\"), checkToken(token,\"tipe\"),token,None,line_ident_level,None))\n",
        "                                    tokens.append(\"<\" + tokens_list[-1]._tipe + \" \" + token + \">\")\n",
        "                        else:\n",
        "                            raise ValueError(f'Erro léxico na linha {linha_numero}: {linha}\\n {token}')\n",
        "    #tokens.append(\"<EOF>\")\n",
        "    tokens_list.append(Token('', \"<EOF>\", \"EOF\",\"EOF\",None,line_ident_level,None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ksPrzpegjtGv"
      },
      "outputs": [],
      "source": [
        "#Analisador sintatico\n",
        "#Analisa os tokens em uma lista de strings\n",
        "#Não foi implementado analise pela lista de obj Token\n",
        "def parse_sintatico(expTokens):\n",
        "    param_index = 0\n",
        "    index = 0\n",
        "    closestDefineId = \"\"\n",
        "    indent_level = 0\n",
        "\n",
        "    while index in range(len(expTokens) -1):\n",
        "      if not expTokens:\n",
        "          raise ValueError('Erro sintatico:Erro de sintaxe: Expressão inesperadamente terminada')\n",
        "\n",
        "      current_token = expTokens[index]\n",
        "\n",
        "      next_token = expTokens[index + 1] if index < len(expTokens) - 1 else None\n",
        "      previous_token = expTokens[index - 1] if index >= 1 else None\n",
        "\n",
        "      #print(\"current token: \" + current_token)\n",
        "      #if next_token:\n",
        "      #  print(\"next token: \" + next_token)\n",
        "      #if previous_token:\n",
        "      #  print(\"previous_token: \" + previous_token)\n",
        "\n",
        "      #================================================\n",
        "      #Expressão dentro de parênteses\n",
        "      #Considera todos os tokens como parametros até encontrar um fechamento\n",
        "      #Ou até percorrer todo arquivo\n",
        "      #Retorna erro se chegar o final do arquivo ou se encontrar uma nova abertura de parenteses\n",
        "      #================================================\n",
        "      #TODO: Ajustar para percorrer parametros até quebra de linha?\n",
        "      if current_token.startswith(\"<ini param\") :\n",
        "          param_index = index + 1\n",
        "          inner_tokens = []\n",
        "          while ( not expTokens[param_index].startswith(\"<fim param\")):\n",
        "            inner_tokens.append(expTokens[param_index])\n",
        "            param_index += 1\n",
        "            if expTokens[param_index].startswith(\"<newline\") :\n",
        "              raise ValueError('Erro de sintaxe: Parêntese de fechamento ausente')\n",
        "          parse_output.append(current_token)\n",
        "          for expr in inner_tokens:\n",
        "            parse_output.append(expr)\n",
        "\n",
        "          index = param_index+1\n",
        "          parse_output.append(expTokens[index])\n",
        "      elif current_token.startswith(\"<ini array\") :\n",
        "          #================================================\n",
        "          # Expressão dentro de colchetes\n",
        "          #================================================\n",
        "          param_index = index + 1\n",
        "          inner_tokens = []\n",
        "          while (param_index != len(expTokens) and not expTokens[param_index].startswith(\"<fim array\")):\n",
        "            inner_tokens.append(expTokens[param_index])\n",
        "            param_index += 1\n",
        "            if expTokens[param_index].startswith(\"<newline\"):\n",
        "              raise ValueError('Erro sintatico:Era esperado fechamento de array antes da quebra de linha')\n",
        "          parse_output.append(current_token)\n",
        "          for expr in inner_tokens:\n",
        "            parse_output.append(expr)\n",
        "\n",
        "          index = param_index\n",
        "          parse_output.append(expTokens[param_index])\n",
        "      #================================================\n",
        "      # Número\n",
        "      #================================================\n",
        "      elif current_token.startswith(\"<num\"):\n",
        "          parse_output.append(current_token)\n",
        "\n",
        "      #================================================\n",
        "      # Identificador\n",
        "      #================================================\n",
        "      elif current_token.startswith(\"<id\"):\n",
        "\n",
        "          if next_token and (next_token.startswith(\"<arithmetic op\") or\n",
        "                            next_token.startswith(\"<relational op\") or\n",
        "                            next_token.startswith(\"<atribuition op\") or\n",
        "                            next_token.startswith(\"<logical op\") or\n",
        "                            next_token.startswith(\"<newline>\") or\n",
        "                            next_token.startswith(\"<tab>\") or\n",
        "                            next_token.startswith(\"<:>\")):\n",
        "            parse_output.append(current_token)\n",
        "\n",
        "          else:\n",
        "              raise ValueError(f'Erro de sintaxe: Identificador \"{current_token}\" seguido por token inesperado \"{next_token}\"')\n",
        "      #================================================\n",
        "      # Operações de atribuição\n",
        "      #================================================\n",
        "      elif current_token.startswith(\"<atribuition op\"):\n",
        "          if not previous_token:\n",
        "            raise ValueError(f'Erro de sintaxe: Nenhuma variavel antes de {current_token}')\n",
        "          if not previous_token.startswith(\"<id\"):\n",
        "            raise ValueError(f'Erro de sintaxe: O token {previous_token} não é compatível com o operador {current_token}')\n",
        "          if next_token and (next_token.startswith(\"<string\") or\n",
        "                            next_token.startswith(\"<num\") or\n",
        "                            next_token.startswith(\"<id\") or\n",
        "                            next_token.startswith(\"<ini param\") or\n",
        "                            next_token.startswith(\"<ini array\")\n",
        "                            ):\n",
        "            parse_output.append(current_token)\n",
        "\n",
        "          else:\n",
        "            raise ValueError(f'Erro de sintaxe: Operador de atribuição \"{current_token}\" seguido por token inesperado \"{next_token}\"')\n",
        "      #================================================\n",
        "      # Operadores aritméticos\n",
        "      #================================================\n",
        "      elif current_token.startswith(\"<arithmetic op\"):\n",
        "          if next_token and (next_token.startswith(\"<num\") or\n",
        "                             next_token.startswith(\"<id\") or\n",
        "                             next_token.startswith(\"<string\")):\n",
        "            parse_output.append(current_token)\n",
        "          else:\n",
        "             raise ValueError(f'Erro de sintaxe: Operador aritmetico \"{current_token}\" seguido por token inesperado \"{next_token}\"')\n",
        "      elif current_token.startswith(\"<relational op\"):\n",
        "        parse_output.append(current_token)\n",
        "\n",
        "      elif current_token.startswith(\"<string\"):\n",
        "        parse_output.append(current_token)\n",
        "\n",
        "      #================================================\n",
        "      # Definição de funções/métodos\n",
        "      #Esqueleto de função aceitavel:\n",
        "      #função \"nomeDaFunção\" (\"parametro1,parametro2,...\"):\n",
        "      #================================================\n",
        "      elif current_token.startswith(\"<def \"):\n",
        "        if not next_token.startswith(\"<id\"):\n",
        "          raise ValueError(f\"Erro sintatico:Token inesperado {next_token} na definição da função {current_token}\")\n",
        "        closestDefineId = next_token\n",
        "        param_index = index + 2\n",
        "        if not expTokens[param_index].startswith(\"<ini param\"):\n",
        "          raise ValueError(f\"Erro sintatico:Era esperado abertura de parenteses, mas foi encontrado {expTokens[param_index]}\")\n",
        "        param_index += 1\n",
        "        func_params = []\n",
        "        while not expTokens[param_index].endswith(\"):>\") and not expTokens[param_index].endswith(\":>\"):\n",
        "          #print(f\"token atual: {expTokens[param_index]}\")\n",
        "          if expTokens[param_index] == \"<newline>\":\n",
        "            raise ValueError(f\"Erro sintatico:Era esperado fechamento de parenteses antes da quebra de linha {expTokens[param_index]} {expTokens[param_index+1]}\")\n",
        "          func_params.append(expTokens[param_index])\n",
        "          param_index += 1\n",
        "\n",
        "        parse_output.append(current_token)\n",
        "        for expr in func_params:\n",
        "            parse_output.append(expr)\n",
        "        parse_output.append(expTokens[param_index])\n",
        "        index = param_index\n",
        "      elif current_token.startswith(\"<ret \"):\n",
        "        #================================================\n",
        "        # Captação de retorna\n",
        "        #================================================\n",
        "        if (not next_token.startswith(\"<id\") and\n",
        "            not next_token.startswith(\"<string\") and\n",
        "            not next_token.startswith(\"<num\")) :\n",
        "          raise ValueError(f\"Erro sintatico:Token inesperado após retorna: {next_token}\")\n",
        "        if not closestDefineId:\n",
        "          raise ValueError(f\"Erro sintatico:Nenhuma função definida antes de return {next_token}\")\n",
        "        #LookUp For Nearest Define function\n",
        "        lookup_index = index\n",
        "        while not expTokens[lookup_index].startswith(\"<def\"):\n",
        "          lookup_index -= 1\n",
        "\n",
        "        if expTokens[lookup_index + 1] != closestDefineId:\n",
        "          raise ValueError(f\"Era esperado o <id> {closestDefineId}, mas foi encontrado {expTokens[lookup_index + 1]}\")\n",
        "        parse_output.append(current_token)\n",
        "      #================================================\n",
        "      # Captação de quebra de linha\n",
        "      #================================================\n",
        "      elif(current_token.startswith(\"<newline\")):\n",
        "        parse_output.append(\"\\n\")\n",
        "      #================================================\n",
        "      # Captação de quebra de tabulação\n",
        "      #================================================\n",
        "      elif(current_token.startswith(\"<tab\")):\n",
        "        parse_output.append(\"\\t\")\n",
        "      elif(current_token == (\" \")):\n",
        "        parse_output.append(\" \")\n",
        "      elif(current_token == (\"<:>\")):\n",
        "      #================================================\n",
        "       # Captação de dois pontos\n",
        "      #================================================\n",
        "        parse_output.append(current_token)\n",
        "      #================================================\n",
        "      # Funções padrões (imprime,para,em,faça,enquanto)\n",
        "      #================================================\n",
        "      elif current_token.startswith(\"<std cmd\"):\n",
        "        if current_token.startswith(\"<std cmd para\"):\n",
        "            #================================================\n",
        "            # Estruturas de controle de fluxo - Para\n",
        "            #Sintaxe aceita: para <id> em <id>\n",
        "            #================================================\n",
        "            param_index = index\n",
        "            if not expTokens[param_index+1].startswith(\"<id\"):\n",
        "              raise ValueError(f'Erro sintatico:Era esperado um token do tipo <id> e foi encontrado {expTokens[param_index+1]}')\n",
        "            if not expTokens[param_index+2] == (\"<std cmd em>\"):\n",
        "              raise ValueError(f'Erro sintatico:Era esperado a instrução \"em\" após <id> e foi encontrado {expTokens[param_index+2]}')\n",
        "            if not expTokens[param_index+3].startswith(\"<id\"):\n",
        "              raise ValueError(f'Erro sintatico:Era esperado um token do tipo <id> e foi encontrado {expTokens[param_index+3]}')\n",
        "            if not \":\" in expTokens[param_index+3] and \":\" not in expTokens[param_index+4] :\n",
        "              raise ValueError(f'Erro sintatico:Não foi encontrado o fechamento \":\" da instrução \"para\" {expTokens[param_index+3]} {expTokens[param_index+4]}')\n",
        "\n",
        "            parse_output.append(current_token)\n",
        "            parse_output.append(expTokens[param_index+1])\n",
        "            parse_output.append(expTokens[param_index+2])\n",
        "            parse_output.append(expTokens[param_index+3])\n",
        "            parse_output.append(expTokens[param_index+4])\n",
        "            index = param_index+4\n",
        "        elif current_token.startswith(\"<std cmd enquanto\"):\n",
        "            #================================================\n",
        "            # Estruturas de controle de fluxo - Enquanto\n",
        "            # A instrução aceita comparação de duas variaveis\n",
        "            #================================================\n",
        "            param_index = index\n",
        "            if not next_token.startswith(\"<id\"):\n",
        "              raise ValueError(f'Erro sintatico:Era esperado um token do tipo id, mas foi encontrado: {next_token} após {current_token}. A instrução \"enquanto\" só aceita comparação entre duas variaveis')\n",
        "\n",
        "            if not expTokens[param_index + 2].startswith(\"<relational op\"):\n",
        "              raise ValueError(f'Erro sintatico:Era esperado um operador relacional, mas foi encontrado: {expTokens[param_index + 2]} após {expTokens[param_index + 1]}')\n",
        "\n",
        "            if not expTokens[param_index + 3].startswith(\"<id\"):\n",
        "              raise ValueError(f'Erro sintatico:Era esperado um token do tipo id, mas foi encontrado: {expTokens[param_index + 3]} após {expTokens[param_index + 2]}. A instrução \"enquanto\" só aceita comparação entre duas variaveis')\n",
        "\n",
        "            parse_output.append(current_token)\n",
        "            parse_output.append(expTokens[param_index + 1])\n",
        "            parse_output.append(expTokens[param_index + 2])\n",
        "            parse_output.append(expTokens[param_index + 3])\n",
        "            parse_output.append(expTokens[param_index + 4])\n",
        "            index = param_index + 4\n",
        "\n",
        "        elif current_token.startswith(\"<std cmd se \"):\n",
        "          #================================================\n",
        "          # Estruturas de controle de fluxo - se\n",
        "          # A instrução aceita comparação de duas variaveis\n",
        "          #================================================\n",
        "          param_index = index\n",
        "          if not next_token.startswith(\"<id\"):\n",
        "            raise ValueError(f'Erro sintatico:Era esperado um token do tipo id, mas foi encontrado: {next_token} após {current_token}. A instrução só aceita comparação entre duas variaveis')\n",
        "\n",
        "          if not expTokens[param_index + 2].startswith(\"<relational op\"):\n",
        "            raise ValueError(f'Erro sintatico:Era esperado um operador relacional, mas foi encontrado: {expTokens[param_index + 2]} após {expTokens[param_index + 1]}')\n",
        "\n",
        "          if not expTokens[param_index + 3].startswith(\"<id\"):\n",
        "            raise ValueError(f'Erro sintatico:Era esperado um token do tipo id, mas foi encontrado: {expTokens[param_index + 3]} após {expTokens[param_index + 2]}. A instrução só aceita comparação entre duas variaveis')\n",
        "\n",
        "\n",
        "          index +=1\n",
        "        elif current_token.startswith(\"<std cmd senaose\"):\n",
        "          #================================================\n",
        "          # Estruturas de controle de fluxo - senaose\n",
        "          # A instrução aceita comparação de duas variaveis\n",
        "          #================================================\n",
        "          param_index = index\n",
        "          if not next_token.startswith(\"<id\"):\n",
        "            raise ValueError(f'Erro sintatico:Era esperado um token do tipo id, mas foi encontrado: {next_token} após {current_token}. A instrução só aceita comparação entre duas variaveis')\n",
        "\n",
        "          if not expTokens[param_index + 2].startswith(\"<relational op\"):\n",
        "            raise ValueError(f'Erro sintatico:Era esperado um operador relacional, mas foi encontrado: {expTokens[param_index + 2]} após {expTokens[param_index + 1]}')\n",
        "\n",
        "          if not expTokens[param_index + 3].startswith(\"<id\"):\n",
        "            raise ValueError(f'Erro sintatico:Era esperado um token do tipo id, mas foi encontrado: {expTokens[param_index + 3]} após {expTokens[param_index + 2]}. A instrução  só aceita comparação entre duas variaveis')\n",
        "          \n",
        "          if not expTokens[param_index + 5].startswith(\"<id\"):\n",
        "            raise ValueError(f' Erro sintatico:Era esperado um token do tipo id, mas foi encontrado: {expTokens[param_index + 3]} após {expTokens[param_index + 2]}. A instrução  só aceita comparação entre duas variaveis')\n",
        "          \n",
        "\n",
        "          parse_output.append(current_token)\n",
        "\n",
        "          index +=1\n",
        "        elif current_token.startswith(\"<std cmd senao:\"):\n",
        "          #================================================\n",
        "          # Estruturas de controle de fluxo - senao\n",
        "          # A instrução aceita comparação de duas variaveis\n",
        "          #================================================\n",
        "          if not next_token == (\"<newline>\"):\n",
        "            raise ValueError(f'Era esperado o final da instrução senao')\n",
        "          parse_output.append(current_token)\n",
        "\n",
        "        elif current_token.startswith(\"<std cmd imprime\"):\n",
        "          #================================================\n",
        "          # Comando imprime - equivalente a print\n",
        "          # A instrução aceita uma variavel ou uma string\n",
        "          #================================================\n",
        "          if not next_token.startswith(\"<ini param\"):\n",
        "            raise ValueError(f'Era esperado abertura de parenteses após {current_token}')\n",
        "          parse_output.append(current_token)\n",
        "          inner_expressions = []\n",
        "          param_index = index +1\n",
        "          while not expTokens[param_index].startswith(\"<fim param\"):\n",
        "            inner_expressions.append(expTokens[param_index]) #TODO: Analisar parametros do imprime\n",
        "            param_index += 1\n",
        "            if expTokens[param_index] == \"<newline>\":\n",
        "              raise ValueError(f'Era esperado fechamento antes da quebra de linha')\n",
        "          for expr in inner_expressions:\n",
        "            parse_output.append(expr)\n",
        "          index = param_index\n",
        "          parse_output.append(expTokens[index])\n",
        "      elif current_token == \"<EOF>\":\n",
        "        pass\n",
        "      else:\n",
        "          raise ValueError(f'Erro de sintaxe: Token inesperado {current_token}')\n",
        "      #print(\"\\n\")\n",
        "      index += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Analisador semantico\n",
        "#Analisa a lista de obj Token\n",
        "#Token possui os seguintes atributos:\n",
        "# translation   -> tradução equivalente em python,\n",
        "# lexicon       -> token no formato <'tipo' 'valor>\n",
        "# tipe          -> tipo do token (string, num, id,etc)\n",
        "# value         -> valor do token, obtido do codigo fonte em pythongol\n",
        "# varTipe       -> Utilizado somente em identificadores\n",
        "#                  recebe o tipo da expressão atribuida à variavel (string, num)\n",
        "\n",
        "def parse_semantico(statementTokens):\n",
        "    index = 0\n",
        "    isInConditionalBlock = False\n",
        "    while index in range(len(statementTokens)):\n",
        "        previous_token = statementTokens[index - 1] if index >= 1 else None\n",
        "        current_token = statementTokens[index]\n",
        "        next_token = statementTokens[index + 1] if index < len(statementTokens) - 1 else None\n",
        "        \n",
        "        #print(f\"STATEMENT: current token {current_token._value}\")\n",
        "        #if next_token :\n",
        "        #    print(f\"next_token  {next_token.value}\")\n",
        "        #if previous_token:\n",
        "        #    print(f\"previous_token  {previous_token.value}\")\n",
        "        \n",
        "        #****************************************************************\n",
        "        #Verificação de declaração de variaveis\n",
        "        if current_token._tipe == \"atribuition op\":\n",
        "            if not previous_token:\n",
        "                raise ValueError(f'Statement error: Nenhum token antes do operador {current_token._value}')\n",
        "            if not previous_token._tipe == \"id\" :\n",
        "                raise ValueError(f'Statement error: O token {previous_token} não suporta operação de atribuição')\n",
        "            if not next_token or next_token._tipe == \"newline\":\n",
        "                raise ValueError(f'Statement error: Nenhum token após o operador {current_token._value}')\n",
        "            \n",
        "\n",
        "            if (next_token._tipe != TIPE_STRING and\n",
        "                next_token._tipe != TIPE_NUM and\n",
        "                next_token._tipe != TIPE_IDENTIF and\n",
        "                next_token._tipe != TIPE_DELIMITADOR_ARRAY_INI and\n",
        "                next_token._tipe != TIPE_DELIMITADOR_PARAM_INI ):\n",
        "                raise ValueError(f'Statement error: Não é possível atribuir {next_token._value} a {previous_token._value}')\n",
        "            \n",
        "            parse_semantico(getParameters(index + 1))\n",
        "            if not isInConditionalBlock:\n",
        "                if previous_token._tipe == TIPE_IDENTIF and not checkDefinedVariablesByValue(previous_token._value):\n",
        "                    setDefinedVariable(previous_token,next_token._tipe)\n",
        "                if previous_token._tipe == TIPE_IDENTIF and checkDefinedVariablesByValue(previous_token._value):\n",
        "                    attVarTipe(previous_token,next_token._tipe)\n",
        "\n",
        "            if next_token._tipe == TIPE_IDENTIF:\n",
        "                if not checkDefinedVariablesByValue(next_token._value):\n",
        "                    raise ValueError(f'Erro semantico: Variavel {next_token._value} não declarada')\n",
        "            index += skipParameters(getParameters(index + 1))\n",
        "\n",
        "        elif current_token._tipe == TIPE_IDENTIF:\n",
        "            if next_token and  next_token._tipe != TIPE_ATRIBUITION_OP:\n",
        "                if not checkDefinedVariablesByValue(current_token._value):\n",
        "                    raise ValueError(f\"Erro semantico: Variavel {current_token._value} não declarada\")\n",
        "        #****************************************************************\n",
        "        #Verificação semantica de operadores\n",
        "        elif current_token._tipe == (\"relational op\"):\n",
        "             if current_token._value != \"diferente\":\n",
        "                if (( previous_token._tipe != TIPE_NUM or next_token._tipe != TIPE_NUM) and\n",
        "                    previous_token._tipe != TIPE_IDENTIF and next_token._tipe != TIPE_IDENTIF):\n",
        "                    raise ValueError(f'Erro semantico: Não é possível comparar {previous_token._value} com {next_token._value} usando o operador {current_token.value}')\n",
        "        elif current_token._tipe == (\"arithmetic op\"):\n",
        "            #****************************************************************\n",
        "            #Operador \"mais\"\n",
        "            if previous_token._tipe == TIPE_IDENTIF:\n",
        "                previous_token_varTipe = getVarTipe(previous_token._value)\n",
        "            if next_token._tipe == TIPE_IDENTIF:\n",
        "                next_token_varTipe = getVarTipe(next_token._value)\n",
        "            if current_token._value == \"mais\":\n",
        "                \n",
        "                #****************************************************************\n",
        "                #Operador \"mais\"\n",
        "                #Operação entre variaveis\n",
        "                if previous_token._tipe == TIPE_IDENTIF and next_token._tipe == TIPE_IDENTIF :    \n",
        "                    if previous_token_varTipe == TIPE_STRING and next_token_varTipe == TIPE_STRING:\n",
        "                        pass\n",
        "                    elif ((previous_token_varTipe == TIPE_STRING and next_token_varTipe != TIPE_STRING) or\n",
        "                          (previous_token_varTipe != TIPE_STRING and next_token_varTipe == TIPE_STRING)):\n",
        "                            raise ValueError(f'Erro semantico: Impossivel concatenar a variavel {previous_token._value} do tipo {previous_token_varTipe} com a variavel {next_token._value} do tipo {next_token_varTipe} utilizando o operador {current_token._value}')\n",
        "                \n",
        "                #****************************************************************\n",
        "                #Operador \"mais\"\n",
        "                #Operação entre variaveis do tipo string\n",
        "                if previous_token._tipe == TIPE_STRING or previous_token_varTipe == TIPE_STRING :\n",
        "                    if next_token._tipe != TIPE_STRING and next_token_varTipe != TIPE_STRING:\n",
        "                        raise ValueError(f'Erro semantico: Impossivel concatenar a variavel {previous_token._value} do tipo {previous_token_varTipe} com a variavel {next_token._value} do tipo {next_token_varTipe} utilizando o operador {current_token._value}')\n",
        "                #****************************************************************\n",
        "                #Operador \"mais\"\n",
        "                #Verificação de operação entre números\n",
        "                if previous_token._tipe == TIPE_NUM and previous_token_varTipe == TIPE_NUM :\n",
        "                    if next_token._tipe != TIPE_NUM or next_token_varTipe != TIPE_NUM:\n",
        "                        raise ValueError(f'Erro semantico: O operador {current_token._value} não aceita operações entre {previous_token._tipe} e {next_token._tipe} ')\n",
        "            #****************************************************************\n",
        "            #Outros operadores aritmeticos (menos,div,multip)\n",
        "            #Verificação de operação entre números\n",
        "            else:\n",
        "                if( (previous_token._tipe == TIPE_NUM and next_token._tipe == TIPE_NUM) or\n",
        "                    (previous_token_varTipe == TIPE_NUM and next_token_varTipe == TIPE_NUM) ):\n",
        "                    index += 1\n",
        "                    continue\n",
        "                #****************************************************************\n",
        "                #Verificação de operação entre variaveis \n",
        "                if previous_token._tipe == TIPE_IDENTIF and next_token._tipe == TIPE_IDENTIF :    \n",
        "                    if previous_token_varTipe == TIPE_NUM and next_token_varTipe == TIPE_NUM:\n",
        "                        pass\n",
        "                    #Se qualquer um dos dois tokens não for uma variavel do tipo num\n",
        "                    elif ((previous_token_varTipe == TIPE_NUM and next_token_varTipe != TIPE_NUM) or\n",
        "                          (previous_token_varTipe != TIPE_NUM and next_token_varTipe == TIPE_NUM)):\n",
        "                            raise ValueError(f' Erro semantico: O operador {current_token._value} não aceita operações entre {previous_token_varTipe} e {next_token_varTipe} ')\n",
        "        #****************************************************************\n",
        "        #Verificação semantica de operadores logicos\n",
        "        # E,OU,etc...\n",
        "        #NÃO IMPLEMENTADO---NÃO IMPLEMENTADO--NÃO IMPLEMENTADO \n",
        "        elif current_token._tipe == TIPE_LOGICAL_OP:\n",
        "           raise ValueError(f'Semantico não implementado para {current_token._value}')\n",
        "        #****************************************************************\n",
        "        #Verificação semantica de expressoes dentro de parenteses\n",
        "        elif current_token._tipe == TIPE_DELIMITADOR_PARAM_INI:\n",
        "            inner_params = getParameters( index + 1)\n",
        "            index += skipParameters(inner_params)\n",
        "            parse_semantico(inner_params)\n",
        "            continue\n",
        "        #****************************************************************\n",
        "        #Verificação semantica de funções padrões\n",
        "        #SE, ENQUANTO, PARA, etc...\n",
        "        elif current_token._tipe == TIPE_DEFAULT_FUNC:\n",
        "            #if current_token._value != \"imprime\" and current_token._value != \"em\":\n",
        "                #parse_conditional_block(index)\n",
        "            if current_token._value == \"se\" or current_token._value == \"enquanto\":\n",
        "                isInConditionalBlock = True\n",
        "                inner_params = getParameters( index + 1)\n",
        "                index += skipParameters(inner_params)\n",
        "                parse_semantico(inner_params)\n",
        "                if checkParametersReturn(inner_params):\n",
        "                    #print(f'Tokens ANTES conditionalBlock SEEM skip {statementTokens[index]._value}')\n",
        "                    index += getConditionalBlock(index + 3, current_token._identLevel,False)\n",
        "                    isInConditionalBlock = False\n",
        "                    #print(f'Tokens após conditionalBlock SEEM skip {statementTokens[index]._value}')\n",
        "                    continue\n",
        "                else:\n",
        "                    #print(f'Tokens ANTES conditionalBlock COOOM skip {statementTokens[index]._value}')\n",
        "                    index += getConditionalBlock(index + 3, current_token._identLevel,True)\n",
        "                    #print(f'Tokens após conditionalBlock COOOM skip {statementTokens[index]._value}')\n",
        "                    isInConditionalBlock = False\n",
        "                    continue\n",
        "\n",
        "            elif current_token._value == \"em\":\n",
        "                if ( getVarTipe(next_token._value) != TIPE_DELIMITADOR_ARRAY_INI and\n",
        "                    getVarTipe(next_token._value) != TIPE_STRING):\n",
        "                    raise ValueError(f'Erro semântico: O elemento {getVarTipe(next_token._value)} não é iteravel')\n",
        "            elif current_token._value == \"para\":\n",
        "                setDefinedVariable(next_token,TIPE_STRING)\n",
        "        elif current_token._tipe == TIPE_FUNC_INIT:\n",
        "             if next_token._tipe == TIPE_IDENTIF and not checkDefinedFunctionByValue(next_token._value):\n",
        "                setDefinedVariable(next_token,TIPE_FUNC_INIT)\n",
        "        elif current_token._tipe == TIPE_RETURN:\n",
        "            if next_token._tipe == TIPE_IDENTIF:\n",
        "                if not checkDefinedVariablesByValue(next_token._value):\n",
        "                    raise ValueError(f'Erro semântico: Variável {next_token._value} não foi declarada')\n",
        "            \n",
        "        index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translateToPython(tokens_list):\n",
        "    str_saida = \"\"\n",
        "    for token in tokens_list:\n",
        "        if token._tipe == \"newline\":\n",
        "            str_saida += (\"\\n\")\n",
        "            continue\n",
        "            #print(\"\\n\")\n",
        "        elif token._tipe == \"tab\":\n",
        "            str_saida += (\"\\t\")\n",
        "            continue\n",
        "            #print(\"\\t\")\n",
        "        elif token._tipe == \" \":\n",
        "            str_saida += (\" \")\n",
        "            continue\n",
        "        else:\n",
        "            #print(f\" Translation: {token.translation}\\n Lexicon: {token.lexicon}\\n Type: {token.tipe}\\n Value: {token.value}\\n\")\n",
        "            str_saida += (token._translation)\n",
        "            str_saida += \" \"\n",
        "    print(\"tradução:\")\n",
        "    print(str_saida)\n",
        "    with open(\"pythongol_output.py\", \"w\", encoding=\"utf-8\") as script_file:\n",
        "        script_file.write(str_saida)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": " Erro semantico: O operador menos não aceita operações entre string e num ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 15\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m parse_identation(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m parse_sintatico(tokens)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m parse_semantico(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m translateToPython()\n",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 15\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m (next_token\u001b[39m.\u001b[39m_tipe \u001b[39m!=\u001b[39m TIPE_STRING \u001b[39mand\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     next_token\u001b[39m.\u001b[39m_tipe \u001b[39m!=\u001b[39m TIPE_NUM \u001b[39mand\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     next_token\u001b[39m.\u001b[39m_tipe \u001b[39m!=\u001b[39m TIPE_IDENTIF \u001b[39mand\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     next_token\u001b[39m.\u001b[39m_tipe \u001b[39m!=\u001b[39m TIPE_DELIMITADOR_ARRAY_INI \u001b[39mand\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     next_token\u001b[39m.\u001b[39m_tipe \u001b[39m!=\u001b[39m TIPE_DELIMITADOR_PARAM_INI ):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mStatement error: Não é possível atribuir \u001b[39m\u001b[39m{\u001b[39;00mnext_token\u001b[39m.\u001b[39m_value\u001b[39m}\u001b[39;00m\u001b[39m a \u001b[39m\u001b[39m{\u001b[39;00mprevious_token\u001b[39m.\u001b[39m_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m parse_semantico(getParameters(index \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isInConditionalBlock:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mif\u001b[39;00m previous_token\u001b[39m.\u001b[39m_tipe \u001b[39m==\u001b[39m TIPE_IDENTIF \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m checkDefinedVariablesByValue(previous_token\u001b[39m.\u001b[39m_value):\n",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m             \u001b[39m#Se qualquer um dos dois tokens não for uma variavel do tipo num\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m             \u001b[39melif\u001b[39;00m ((previous_token_varTipe \u001b[39m==\u001b[39m TIPE_NUM \u001b[39mand\u001b[39;00m next_token_varTipe \u001b[39m!=\u001b[39m TIPE_NUM) \u001b[39mor\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m                   (previous_token_varTipe \u001b[39m!=\u001b[39m TIPE_NUM \u001b[39mand\u001b[39;00m next_token_varTipe \u001b[39m==\u001b[39m TIPE_NUM)):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m                     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Erro semantico: O operador \u001b[39m\u001b[39m{\u001b[39;00mcurrent_token\u001b[39m.\u001b[39m_value\u001b[39m}\u001b[39;00m\u001b[39m não aceita operações entre \u001b[39m\u001b[39m{\u001b[39;00mprevious_token_varTipe\u001b[39m}\u001b[39;00m\u001b[39m e \u001b[39m\u001b[39m{\u001b[39;00mnext_token_varTipe\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39m#****************************************************************\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39m#Verificação semantica de operadores logicos\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m \u001b[39m# E,OU,etc...\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m \u001b[39m#NÃO IMPLEMENTADO---NÃO IMPLEMENTADO--NÃO IMPLEMENTADO \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X20sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m \u001b[39melif\u001b[39;00m current_token\u001b[39m.\u001b[39m_tipe \u001b[39m==\u001b[39m TIPE_LOGICAL_OP:\n",
            "\u001b[1;31mValueError\u001b[0m:  Erro semantico: O operador menos não aceita operações entre string e num "
          ]
        }
      ],
      "source": [
        "clearAllLists()\n",
        "#Erro de concatenação entre uma string e num com operador \"mais\"\n",
        "arquivo1 = open('test 1.txt', 'r')\n",
        "lexicon(arquivo1)\n",
        "parse_identation(tokens_list)\n",
        "parse_sintatico(tokens)\n",
        "parse_semantico(tokens_list)\n",
        "translateToPython()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Erro de sintaxe: Operador de atribuição \"<atribuition op recebe>\" seguido por token inesperado \"<std cmd para>\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 16\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lexicon(arquivo2)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m parse_identation(tokens_list)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m parse_sintatico(tokens)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m parse_semantico(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m translateToPython()\n",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m       parse_output\u001b[39m.\u001b[39mappend(current_token)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mErro de sintaxe: Operador de atribuição \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcurrent_token\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m seguido por token inesperado \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnext_token\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m#================================================\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39m# Operadores aritméticos\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39m#================================================\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X21sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39melif\u001b[39;00m current_token\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m<arithmetic op\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "\u001b[1;31mValueError\u001b[0m: Erro de sintaxe: Operador de atribuição \"<atribuition op recebe>\" seguido por token inesperado \"<std cmd para>\""
          ]
        }
      ],
      "source": [
        "clearAllLists()\n",
        "#Teste de atribuição com função padrão\n",
        "# a recebe imprime\n",
        "arquivo2 = open('test 2.txt', 'r')\n",
        "lexicon(arquivo2)\n",
        "parse_identation(tokens_list)\n",
        "parse_sintatico(tokens)\n",
        "parse_semantico(tokens_list)\n",
        "translateToPython()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Erro semantico: Variavel z não declarada",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 17\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m parse_identation(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m parse_sintatico(tokens)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m parse_semantico(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m translateToPython(tokens_list)\n",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 17\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mif\u001b[39;00m next_token \u001b[39mand\u001b[39;00m  next_token\u001b[39m.\u001b[39m_tipe \u001b[39m!=\u001b[39m TIPE_ATRIBUITION_OP:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m checkDefinedVariablesByValue(current_token\u001b[39m.\u001b[39m_value):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mErro semantico: Variavel \u001b[39m\u001b[39m{\u001b[39;00mcurrent_token\u001b[39m.\u001b[39m_value\u001b[39m}\u001b[39;00m\u001b[39m não declarada\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#****************************************************************\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m#Verificação semantica de operadores\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X22sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39melif\u001b[39;00m current_token\u001b[39m.\u001b[39m_tipe \u001b[39m==\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mrelational op\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "\u001b[1;31mValueError\u001b[0m: Erro semantico: Variavel z não declarada"
          ]
        }
      ],
      "source": [
        "clearAllLists()\n",
        "\n",
        "arquivo3 = open('test 3.txt', 'r')\n",
        "lexicon(arquivo3)\n",
        "parse_identation(tokens_list)\n",
        "parse_sintatico(tokens)\n",
        "parse_semantico(tokens_list)\n",
        "translateToPython(tokens_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Erro de idenntação: Identação inesperada",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 18\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m arquivo4 \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtest 4.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lexicon(arquivo4)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m parse_identation(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m parse_sintatico(tokens)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m parse_semantico(tokens_list)\n",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m current_token\u001b[39m.\u001b[39m_value \u001b[39mand\u001b[39;00m next_token\u001b[39m.\u001b[39m_tipe \u001b[39m==\u001b[39m TIPE_NEWLINE):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m         \u001b[39mif\u001b[39;00m listTokens[index \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m]\u001b[39m.\u001b[39m_identLevel \u001b[39m>\u001b[39m current_identation:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mErro de idenntação: Identação inesperada\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X23sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "\u001b[1;31mValueError\u001b[0m: Erro de idenntação: Identação inesperada"
          ]
        }
      ],
      "source": [
        "#Erro de identação\n",
        "clearAllLists()\n",
        "\n",
        "arquivo4 = open('test 4.txt', 'r')\n",
        "\n",
        "lexicon(arquivo4)\n",
        "parse_identation(tokens_list)\n",
        "parse_sintatico(tokens)\n",
        "parse_semantico(tokens_list)\n",
        "translateToPython(tokens_list)\n",
        "output = !python pythongol_output.py\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Erro semantico: Variavel z não declarada",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 19\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m parse_identation(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m parse_sintatico(tokens)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m parse_semantico(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m translateToPython(tokens_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput do arquivo executavel:\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 19\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mif\u001b[39;00m next_token \u001b[39mand\u001b[39;00m  next_token\u001b[39m.\u001b[39m_tipe \u001b[39m!=\u001b[39m TIPE_ATRIBUITION_OP:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m checkDefinedVariablesByValue(current_token\u001b[39m.\u001b[39m_value):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mErro semantico: Variavel \u001b[39m\u001b[39m{\u001b[39;00mcurrent_token\u001b[39m.\u001b[39m_value\u001b[39m}\u001b[39;00m\u001b[39m não declarada\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#****************************************************************\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m#Verificação semantica de operadores\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X24sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39melif\u001b[39;00m current_token\u001b[39m.\u001b[39m_tipe \u001b[39m==\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mrelational op\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "\u001b[1;31mValueError\u001b[0m: Erro semantico: Variavel z não declarada"
          ]
        }
      ],
      "source": [
        "clearAllLists()\n",
        "\n",
        "arquivo5 = open('PyGenius.txt', 'r')\n",
        "\n",
        "lexicon(arquivo5)\n",
        "parse_identation(tokens_list)\n",
        "parse_sintatico(tokens)\n",
        "parse_semantico(tokens_list)\n",
        "translateToPython(tokens_list)\n",
        "\n",
        "print(f\"output do arquivo executavel:\")\n",
        "output = !python pythongol_output.py\n",
        "output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tradução:\n",
            "a = 1 \n",
            "b = 2 \n",
            "i = 0 \n",
            "nome = 'Carlos' \n",
            "t = 4 \n",
            "\n",
            "\n",
            "c = a + b \n",
            "d = a - b \n",
            "e = b * i \n",
            "f = b / a \n",
            "print ( c ) \n",
            "print ( 'ola mundo' ) \n",
            "\n",
            "\n",
            "carros = [ 'ford' , 'fiat' , 'nissan' ] \n",
            "for carro in carros : \n",
            "\tprint ( carro ) \n",
            "\n",
            "while t < a: \n",
            "\tprint ( 'a menor que b' ) \n",
            "\ta = 3 \n",
            "\n",
            "def ola ( nome ) : \n",
            "\tstr = 'Ola' + nome + 'seja bem vindo!' \n",
            "\treturn str \n",
            "\n",
            "if a < b : \n",
            "\tz = 2 \n",
            "\n",
            "print ( z )  \n",
            "output do arquivo executavel:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['3', 'ola mundo', 'ford', 'fiat', 'nissan', '2']"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clearAllLists()\n",
        "\n",
        "arquivo5 = open('test 5.txt', 'r')\n",
        "\n",
        "lexicon(arquivo5)\n",
        "parse_identation(tokens_list)\n",
        "parse_sintatico(tokens)\n",
        "parse_semantico(tokens_list)\n",
        "translateToPython(tokens_list)\n",
        "\n",
        "print(f\"output do arquivo executavel:\")\n",
        "output = !python pythongol_output.py\n",
        "output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Erro léxico na linha 4: nome recebe 'Carlos\n\n 'Carlos",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 21\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clearAllLists()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m arquivo6 \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtest 6.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lexicon(arquivo6)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m parse_identation(tokens_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m parse_sintatico(tokens)\n",
            "\u001b[1;32mc:\\Users\\gusta\\OneDrive\\Documentos\\FACENS\\10Sem\\compiladores\\AF\\Pythongol.ipynb Célula 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     tokens\u001b[39m.\u001b[39mappend(T_STRING \u001b[39m%\u001b[39m token)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39melif\u001b[39;00m token\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m token\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mErro léxico na linha \u001b[39m\u001b[39m{\u001b[39;00mlinha_numero\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mlinha\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mtoken\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39melif\u001b[39;00m token \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gusta/OneDrive/Documentos/FACENS/10Sem/compiladores/AF/Pythongol.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     tokens\u001b[39m.\u001b[39mappend(T_TAB)\n",
            "\u001b[1;31mValueError\u001b[0m: Erro léxico na linha 4: nome recebe 'Carlos\n\n 'Carlos"
          ]
        }
      ],
      "source": [
        "clearAllLists()\n",
        "\n",
        "arquivo6 = open('test 6.txt', 'r')\n",
        "\n",
        "lexicon(arquivo6)\n",
        "parse_identation(tokens_list)\n",
        "parse_sintatico(tokens)\n",
        "parse_semantico(tokens_list)\n",
        "translateToPython(tokens_list)\n",
        "\n",
        "print(f\"output do arquivo executavel:\")\n",
        "output = !python pythongol_output.py\n",
        "output\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
